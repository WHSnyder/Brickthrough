{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Radio Frequency Interference mitigation using deep convolutional neural networks\n",
    "\n",
    "### This example demonstrates how tf_unet is trained on the 'Bleien Galactic Survey data'. \n",
    "\n",
    "To create the training data the SEEK package (https://github.com/cosmo-ethz/seek) has to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/will/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "#plt.rcParams['image.cmap'] = 'rgb'\n",
    "sys.path.append(\"/home/will/projects/legoproj/unetfalse\")\n",
    "sys.path.append(\"/home/will/projects/legoproj/unetfalse/tf_unet\")\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf_unet.image_util.NormalsDataProvider"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_unet import util as tfu\n",
    "from tf_unet import unet\n",
    "from tf_unet import image_util as imu\n",
    "imu.NormalsDataProvider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "files = glob.glob('/home/will/projects/legoproj/data/normz/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files used: 9337\n",
      "Number of channels: 3\n",
      "Number of classes: 3\n",
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:189: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:58,894 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:189: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:194: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:58,895 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:194: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-11-12 12:51:58,898 Layers 3, features 32, filter size 3x3, pool size: 2x2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:25: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:58,910 From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:25: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:39: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:58,932 From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:39: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:48: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:58,949 From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:48: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:151: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,198 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:151: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:161: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,212 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:161: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:68: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,428 From /home/will/projects/legoproj/unetfalse/tf_unet/layers.py:68: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_provider = imu.NormalsDataProvider(\"/home/will/projects/legoproj/data/normz/*\")\n",
    "\n",
    "net = unet.Unet(3,3,cost_kwargs=dict(regularizer=0.001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the network\n",
    "only one epoch. For good results many more are neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:367: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,457 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:367: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:340: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,462 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:340: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:346: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,469 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:346: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:374: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,860 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:374: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:375: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:51:59,864 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:375: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "2019-11-12 12:51:59,867 Removing '/home/will/projects/legoproj/shotsinthedark/prediction'\n",
      "2019-11-12 12:51:59,868 Removing '/home/will/projects/legoproj/shotsinthedark/data/model'\n",
      "2019-11-12 12:51:59,870 Allocating '/home/will/projects/legoproj/shotsinthedark/prediction'\n",
      "2019-11-12 12:51:59,871 Allocating '/home/will/projects/legoproj/shotsinthedark/data/model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:432: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:52:00,337 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:432: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "2019-11-12 12:52:00,574 Start optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 353585.4375\n",
      "Loss is 610867.4375\n",
      "Loss is 623312.875\n",
      "Loss is 256471.984375\n",
      "Loss is 503166.0\n",
      "Loss is 594678.0\n",
      "Loss is 172209.015625\n",
      "Loss is 517486.03125\n",
      "Loss is 1215334.0\n",
      "Loss is 161414.015625\n",
      "Loss is 1444489.0\n",
      "Loss is 362546.03125\n",
      "Loss is 272593.03125\n",
      "Loss is 387190.03125\n",
      "Loss is 160765.015625\n",
      "Loss is 523157.03125\n",
      "Loss is 166712.015625\n",
      "Loss is 7118484.0\n",
      "Loss is 368678.03125\n",
      "Loss is 239664.015625\n",
      "Loss is 143247.015625\n",
      "Loss is 319796.03125\n",
      "Loss is 2810796.0\n",
      "Loss is 253126.015625\n",
      "Loss is 3846060.0\n",
      "Loss is 2122076.0\n",
      "Loss is 797930.0\n",
      "Loss is 195636.015625\n",
      "Loss is 1763799.0\n",
      "Loss is 229183.015625\n",
      "Loss is 1975060.0\n",
      "Loss is 1382920.0\n",
      "Loss is 356593.03125\n",
      "Loss is 419986.03125\n",
      "Loss is 2006990.0\n",
      "Loss is 276112.03125\n",
      "Loss is 4540325.0\n",
      "Loss is 938174.0\n",
      "Loss is 613438.0\n",
      "Loss is 1020669.0\n",
      "Loss is 336647.03125\n",
      "Loss is 253181.015625\n",
      "Loss is 194811.015625\n",
      "Loss is 1332581.0\n",
      "Loss is 261164.015625\n",
      "Loss is 602600.0\n",
      "Loss is 124221.015625\n",
      "Loss is 188323.015625\n",
      "Loss is 171804.015625\n",
      "Loss is 681843.0\n",
      "Loss is 150923.015625\n",
      "Loss is 227182.015625\n",
      "Loss is 429003.03125\n",
      "Loss is 1965820.0\n",
      "Loss is 528997.0\n",
      "Loss is 782209.0\n",
      "Loss is 188659.015625\n",
      "Loss is 240090.015625\n",
      "Loss is 362348.03125\n",
      "Loss is 634502.0\n",
      "Loss is 289198.03125\n",
      "Loss is 149006.015625\n",
      "Loss is 496721.03125\n",
      "Loss is 493001.03125\n",
      "Loss is 136613.015625\n",
      "Loss is 138997.015625\n",
      "Loss is 451067.03125\n",
      "Loss is 262662.03125\n",
      "Loss is 458164.03125\n",
      "Loss is 154423.015625\n",
      "Loss is 181894.015625\n",
      "Loss is 159447.015625\n",
      "Loss is 175664.015625\n",
      "Loss is 2607023.0\n",
      "Loss is 415444.03125\n",
      "Loss is 219592.015625\n",
      "Loss is 504957.03125\n",
      "Loss is 268863.03125\n",
      "Loss is 523637.03125\n",
      "Loss is 274586.03125\n",
      "Loss is 657912.0\n",
      "Loss is 124208.015625\n",
      "Loss is 118759.015625\n",
      "Loss is 163933.015625\n",
      "Loss is 632222.0\n",
      "Loss is 457995.03125\n",
      "Loss is 188342.015625\n",
      "Loss is 438356.03125\n",
      "Loss is 452003.03125\n",
      "Loss is 942161.0\n",
      "Loss is 251412.015625\n",
      "Loss is 178203.015625\n",
      "Loss is 315303.03125\n",
      "Loss is 295512.03125\n",
      "Loss is 274477.03125\n",
      "Loss is 178604.015625\n",
      "Loss is 177911.015625\n",
      "Loss is 138306.015625\n",
      "Loss is 456293.03125\n",
      "Loss is 399481.03125\n",
      "Loss is 1105202.0\n",
      "Loss is 178085.015625\n",
      "Loss is 301679.03125\n",
      "Loss is 809436.0\n",
      "Loss is 1008498.0\n",
      "Loss is 1810167.0\n",
      "Loss is 599329.0\n",
      "Loss is 942699.0\n",
      "Loss is 1241440.0\n",
      "Loss is 1694735.0\n",
      "Loss is 181239.015625\n",
      "Loss is 865588.0\n",
      "Loss is 447914.03125\n",
      "Loss is 225489.015625\n",
      "Loss is 255023.015625\n",
      "Loss is 218888.015625\n",
      "Loss is 170167.015625\n",
      "Loss is 390013.03125\n",
      "Loss is 823545.0\n",
      "Loss is 1841813.0\n",
      "Loss is 114530.015625\n",
      "Loss is 840723.0\n",
      "Loss is 145400.015625\n",
      "Loss is 609227.0\n",
      "Loss is 1272247.0\n",
      "Loss is 1425619.0\n",
      "Loss is 161674.015625\n",
      "Loss is 2005930.0\n",
      "Loss is 190839.015625\n",
      "Loss is 474887.03125\n",
      "Loss is 523681.03125\n",
      "Loss is 722140.0\n",
      "Loss is 238107.015625\n",
      "Loss is 1021057.0\n",
      "Loss is 128900.015625\n",
      "Loss is 497909.03125\n",
      "Loss is 182883.015625\n",
      "Loss is 3725191.0\n",
      "Loss is 156320.015625\n",
      "Loss is 176833.015625\n",
      "Loss is 8447198.0\n",
      "Loss is 1009586.0\n",
      "Loss is 1179361.0\n",
      "Loss is 2006990.0\n",
      "Loss is 415958.03125\n",
      "Loss is 506676.03125\n",
      "Loss is 331243.03125\n",
      "Loss is 100540.015625\n",
      "Loss is 143631.015625\n",
      "Loss is 1005282.0\n",
      "Loss is 1253873.0\n",
      "Loss is 288149.03125\n",
      "Loss is 527450.0\n",
      "Loss is 105207.015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:52:08,406 Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 1410106.0\n",
      "Loss is 147315.015625\n",
      "Loss is 235364.015625\n",
      "Loss is 477438.03125\n",
      "Loss is 587788.0\n",
      "Loss is 547401.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = unet.Trainer(net, optimizer=\"momentum\", opt_kwargs=dict(momentum=0.2))\n",
    "path = trainer.train(data_provider, \"./data/model\", \n",
    "                     training_iters=32, \n",
    "                     epochs=5, \n",
    "                     dropout=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running the prediction on the trained unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files used: 9337\n",
      "Number of channels: 3\n",
      "Number of classes: 3\n",
      "WARNING:tensorflow:From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:308: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:52:08,578 From /home/will/projects/legoproj/unetfalse/tf_unet/unet.py:308: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 12:52:08,618 From /home/will/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The passed save_path is not a valid checkpoint: ./data/model/model.ckpt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-433ccdc14f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalsDataProvider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/will/projects/legoproj/data/normz/*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#DataProvider(10000, files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/legoproj/unetfalse/tf_unet/unet.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model_path, x_test)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;31m# Restore model weights from previously saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0my_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/legoproj/unetfalse/tf_unet/unet.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, model_path)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored from file: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n\u001b[0;32m-> 1278\u001b[0;31m                        compat.as_text(save_path))\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: ./data/model/model.ckpt"
     ]
    }
   ],
   "source": [
    "data_provider = imu.NormalsDataProvider(\"/home/will/projects/legoproj/data/normz/*\")#DataProvider(10000, files)\n",
    "x_test, y_test = data_provider(1)\n",
    "prediction = net.predict(path, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(12,4))\n",
    "ax[0].imshow(x_test[0,...,0], aspect=\"auto\")\n",
    "ax[1].imshow(y_test[0,...,1], aspect=\"auto\")\n",
    "ax[2].imshow(prediction[0,...,1], aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
